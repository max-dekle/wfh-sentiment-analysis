# Machine Learning Method 2
# Sentiment Regression Write-Up

## Why did you use this statistical test or ML algorithm? Which other tests did you consider or evaluate? What metric(s) did you use to measure success or failure, and why did you use it? What challenges did you face evaluating the model? Did you have to clean or restructure your data?
We used both linear regression and a t-test to determine how effective our model was at predicting future sentiment. Our t-test performed best since, unsurprisingly, our X and Y are independent. They are independent because X contains all articles written in 2020-2021 and Y has those written in 2022-2023; there is otherwise no link between them.

To be able to adapt linear regression to this model, we needed to create a dependent relationship between X and Y. Therefore, we split them up by week instead; does the sentiment of articles written in early Jan 2020 & Jan 2021 impact the sentiment of articles later written in early Jan 2022 and Jan 2023? 

Because it can capture linear correlations between the input (past sentiment scores) and output (future sentiment scores) fairly effectively, linear regression is a very viable option for forecasting future sentiment scores based on past ones. A linear regression model can successfully capture this relationship and provide reliable forecasts if there is a strong linear relationship between the two sets of ratings, which we believe there may be especially in the aftermath of the COVID-19 pandemic. Although logistic regression was a possibility we considered implementing, it is more frequently used to classify outputs rather than to provide continuous values, so in this situation, linear regression is a better fit for our goals. 

We settled on two metrics to evaluate our model's effectiveness: r-squared (coefficient of determination) and also MSE (mean squared error). R-squared, also known as the coefficient of determination, is a statistical indicator that shows how much variance the regression model is able to account for. It has a value between 0 and 1, with a higher number denoting a better fit. A high R-squared value in the context of linear regression models indicates that the model can effectively account for a sizable proportion of the variance in the dependent variable by adjusting the independent variables. R-squared is a useful metric for assessing a linear regression model's goodness of fit because of this. Mean squared error, also known as the average squared difference between the dependent variable's expected and actual values, is another viable metric. A low MSE value in the context of linear regression models indicates that the model is capable of producing precise predictions with minimal errors. As a result, MSE is a useful indicator for assessing how well a linear regression model predicts the future.

One issue we ran into was over-fitting. To help combat this, we implemented k-fold cross validation to help split our data into smaller train and test sets so as to let our model see as many combinations of data as possible. We also had to drop 2 entries from the 2020/2021 dataset to make it the same size as the 2022/2023 dataset. Additionally, we had to remove the IDs and only keep the sentiment scores, since the model had trouble interpreting strings in its analysis. 

## What is your interpretation of the results? Do you accept or deny the hypothesis, or are you satisfied with your prediction accuracy? For prediction projects, we expect you to argue why you got the accuracy/success metric you have. Intuitively, how do you react to the results? Are you confident in the results?

Our mean r2 value is very low at 0.009, as is our mean MSE value as 0.05. This is interesting because usually a high r2 and low MSE is indicitive of an effective model, but in our case our r2 value suggests that our model is ineffective, whereas the low MSE implies the opposite. 

A low MSE indicates that the predicted values are very close to the actual values. In other words, the model predicts the outcome variable with reasonable accuracy. Even though the model is producing somewhat accurate predictions, the presence of a low R-squared value, as in our example, shows that the model is unfortunately not explaining much of the variance in the outcome variable. It is important to note that while MSE is a measure of how well the model is predicting the actual values, R-squared is a measure of how well the model is explaining the variability in the outcome variable based on the predictors. Thus, while a low MSE is desirable, a low R-squared value may suggest that there are other variables that should be included in the model, or perhaps that a different model should be used altogether.

Therefore, we can conclude that our results are statistically insignificant by virtue of our low r-squared value, and fail to prove the hypothesis that remote work has received an increasingly positive sentiment in recent years. In a sense, it makes sense that remote work may not necessarily become increasingly popular in recent years, especially since our dataset starts in 2020 during the COVID pandemic when remote work became a necessity. We are confident in the results since we tried out different variations of the model, different ways of splitting the dataset, and contextually we can deduce that remote work may not necessarily have become significantly more popular in recent years. 
